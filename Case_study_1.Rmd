---
title: "Bike Sharing Case Study"
author: "Ashish"
date: "25/07/2021"
output: md_document
---
> **Tables of Contents**

* Introduction

* Ask
  + Guiding Questions
  + Key tasks
  + Deliverable
  
* Prepare
  + Guiding questions
  + Key Tasks
  * Deliverable

* Process
  + Code
    + Dependence
    + Concatenating
    + Data Cleaning
    + Manipulating the data
    + Saving the result as a csv
  + Guiding questions
  + Key tasks
  * Deliverable

* Analyze
  + Code
    + Data Distribution
    + Other variables
  + Guiding questions
  + Key Tasks
  * Deliverable

* Share
  + Guiding questions
  + Key Tasks
  * Deliverable

* Act
  + Guiding questions
  + Key Tasks
  * Deliverable

* Conclusion

## Introduction

This is my version of the Google Data Analytics Capstone Case Study 1. The full documentation to the case study can be found
in the [Google Data Analytics Capstone: Complete a Case Study](https://www.coursera.org/learn/google-data-analytics-capstone) course.

For this project, the following steps will be followed to ensure its completion: --

  + It will follow the steps of the data analysis process: Ask, Prepare, Process, Analyze, Share and Act
  + Each step will follow its own roadmap with: --
    + code, if needed on the step.
    + Guiding question, with answers.
    + Key tasks, as a checklist.
    + Deliverable, as a checklist.

## Ask

For the ask step, first, let's get some context from the cyclists document: 

### Guiding questions

+ **What is the problem you are trying to solve?**

The main objective is to determine a way to build a profile for annual members and the best marketing strategies to turn casual bike riders into annual members.

+ **How can your insight drive business decisions?**

The insight will help the marketing team to increase annual member

### Key tasks

+ [X] Identify the business task
+ [X] Consider Key stakeholders

### Deliverable

+ [X] A Clear Statement of the business task
Find the keys differences between casual and members riders and how digital media could influence them

## Prepare

The project will use the data provided by this [Kaggle dataset](https://www.kaggle.com/timgid/cyclistic-dataset-google-certificate-capstone)

### Guiding questions

+ **Where is your data located?**

The data is located in kaggle dataset.

+ **How is the data organized?**

The data is separated by month, each on its own *CSV*.

+ **How are you addressing licensing, privacy, security and accessibility?**

The company has their own license over the dataset. Besides that, the dataset doesn't have any personal information about the riders.

+ **How did you verify the data's integrity?**

All the files have consistent columns and each column has the correct type of data.

+ **How does it help you answer your question?**

It may have some key insight about riders and their riding style.

+ **are there any problems with the data?**

It would be good to have some updated information about the bike stations. Also more information about the riders could be useful.

### Key tasks

* [X] Download data and store it appropriately.
* [X] Identify how its organized.
* [X] Determine the credibility of the data.

### Deliverable

* [X] A description of all data source used
The main data source is 12 months (Between April 2020 and march 2021) of riding data provided by the Cicylistic Company.

## Process

This step will prepare the data for analysis. All the csv files will be merged into one file to improve workflow.

### Code

```{r warning=FALSE}
library(tidyverse)
library(lubridate)
```

**Importing Data**

###### import data

```{r}
#loading data-sets 
q1_2020 <- read_csv("Divvy_Trips_2020_Q1.csv")
q2_2019 <- read_csv("Divvy_Trips_2019_Q2.csv")
q3_2019 <- read_csv("Divvy_Trips_2019_Q3.csv")
q4_2019 <- read_csv("Divvy_Trips_2019_Q4.csv")
```


###### Wrangle data
```{r}
#Rename columns to make them consistent with q1_2020.
q2_2019 <- q2_2019 %>% rename(ride_id = "01 - Rental Details Rental ID",
                              rideable_type = "01 - Rental Details Bike ID",
                              started_at = "01 - Rental Details Local Start Time",
                              ended_at = "01 - Rental Details Local End Time"
                              ,start_station_name = "03 - Rental Start Station Name" 
                              ,start_station_id = "03 - Rental Start Station ID"
                              ,end_station_name = "02 - Rental End Station Name" 
                              ,end_station_id = "02 - Rental End Station ID"
                              ,member_casual = "User Type")

q3_2019 <- q3_2019 %>% rename(ride_id = "trip_id",
                              rideable_type = "bikeid",
                              started_at = "start_time",
                              ended_at = "end_time"
                              ,start_station_name = "from_station_name" 
                              ,start_station_id = "from_station_id"
                              ,end_station_name = "to_station_name" 
                              ,end_station_id = "to_station_id"
                              ,member_casual = "usertype")

q4_2019 <- q4_2019 %>% rename(ride_id = "trip_id",
                              rideable_type = "bikeid",
                              started_at = "start_time",
                              ended_at = "end_time"
                              ,start_station_name = "from_station_name" 
                              ,start_station_id = "from_station_id"
                              ,end_station_name = "to_station_name" 
                              ,end_station_id = "to_station_id"
                              ,member_casual = "usertype")
```

```{r}
#converting ride_id and rideable_type to character so they can stack easily:
q2_2019 <- mutate(q2_2019,ride_id = as.character(ride_id),
                  rideable_type = as.character(rideable_type))
q3_2019 <- mutate(q3_2019,ride_id = as.character(ride_id),
                  rideable_type = as.character(rideable_type))
q4_2019 <- mutate(q4_2019,ride_id = as.character(ride_id),
                  rideable_type = as.character(rideable_type))
```

#### Concatenating.

All the CSV files will be concatenated into one dataframe.
```{r}
#stacking individual data frames into one.
all_trips_df <- bind_rows(q1_2020,q2_2019,q3_2019,q4_2019)
head(all_trips_df)

#Remove extra columns.
all_trips_df <- all_trips_df %>% select(-c(start_lat,start_lng,end_lat,
                                           end_lng,birthyear,gender,"01 - Rental Details Duration In Seconds Uncapped",
                                           "05 - Member Details Member Birthday Year","Member Gender","tripduration"))
```


#### Data Cleaning.

##### Removing Duplicates
```{r}
all_trips_df_no_dups = all_trips_df[!duplicated(all_trips_df$ride_id),]
print(paste("Removed", nrow(all_trips_df)-nrow(all_trips_df_no_dups),"duplicate rows"))

```

```{r}
table(all_trips_df$member_casual) #seeing how many observation fall under each userType

#Reassign to the desired values.
all_trips_df <- all_trips_df %>% mutate(member_casual = recode(member_casual, "Subscriber" = "member","Customer" = "casual"))

table(all_trips_df$member_casual) #check to make sure the proper number of observation.

```

##### Parsing datetime columns

```{r}
# Add columns that list the date, month, day, and year of each ride
all_trips_df$date <- as.Date(all_trips_df$started_at)
all_trips_df$month  <- format(as.Date(all_trips_df$date), "%m")
all_trips_df$day <- format(as.Date(all_trips_df$date),"%d")
all_trips_df$year <- format(as.Date(all_trips_df$date),"%Y")
all_trips_df$day_of_week <- format(as.Date(all_trips_df$date),"%A")
all_trips_df <- all_trips_df %>%
    mutate(year_month = paste(strftime(all_trips_df$started_at, "%Y"),
                              "-",
                              strftime(all_trips_df$started_at, "%m"),
                              paste("(",strftime(all_trips_df$started_at, "%b"), ")", sep="")))
all_trips_df <- all_trips_df %>%
    mutate(start_hour = strftime(all_trips_df$ended_at, "%H"))
```


#### Manipulating the data

##### ride length
the total time of a bike ride, in minutes

```{r}
all_trips_df$ride_length <- (difftime(all_trips_df$ended_at,all_trips_df$started_at)/60)
```

```{r}
#convert ride_length from factor to numeric for ease in calculation
all_trips_df$ride_length <- as.numeric(as.character(all_trips_df$ride_length))
summary(all_trips_df$ride_length)

#remove bad data
all_trips_df_v2 <- all_trips_df[!(all_trips_df$start_station_name == "HQ QR"|all_trips_df$ride_length<0),]
```

### Guiding questions

+ **What tools are you choosing and why?**

I'm using R for this project, for two main reasons: Because of the large dataset and to gather experience with the language.

+ **Have you ensured your data's integrity?**

Yes, the data is consistent throughout the columns.

+ **What steps have you taken to ensure that your data is clean?**

First the duplicates values where removed, then the columns where formatted to their correct format.

+ **How can you verify that your data is clean and ready to analyze?**

It can be verified by this notebook.

+ **Have you documented your cleaning process so you can review and share those result?**

Yes, It's all documented in this R notebook.

### Key tasks

* [X] Check the data for errors.
* [X] Choose your tools.
* [X] Transform the data so you can work with it effectively.
* [X] Document the cleaning process.

### Deliverable

* [X] Documentation of any cleaning or manipulation of data.

## Analyze

The data exploration will consist of building a profile for annual members and how they differ from casual riders.

Putting in a new variable with a simpler name will help reduce some typing in the future.

#### Code

To quick start, let's generate a summary of the dataset.

```{r}
summary(all_trips_df_v2)
```

##### Casuals vs members

How much of the data is about members and how much is about casuals?

```{r}
all_trips_df_v2 %>% group_by(member_casual) %>% summarise(count = length(ride_id),'%' = (length(ride_id)/ nrow(all_trips_df_v2))*100)
```
```{r}
# Compare members and casual users
aggregate(all_trips_df_v2$ride_length ~ all_trips_df_v2$member_casual, FUN = mean)
aggregate(all_trips_df_v2$ride_length ~ all_trips_df_v2$member_casual, FUN = median)
aggregate(all_trips_df_v2$ride_length ~ all_trips_df_v2$member_casual, FUN = max)
aggregate(all_trips_df_v2$ride_length ~ all_trips_df_v2$member_casual, FUN = min)

```


```{r}
fig <- function(width,height){options(repr.plot.width = width,repr.plot.height = height)}

```

```{r}
fig(16,8)
ggplot(data = all_trips_df_v2) + geom_bar(mapping  = aes(member_casual, fill = member_casual)) + labs(x = "Casual x Members", title = "Chart 01 - Casuals x Members distribution")

```


As we can see on the member x casual table, members have a bigger proportion of the dataset, composing ~76%, ~53% bigger than the count of casual riders.

##### Month

How much of the data is distributed by month?


```{r}
all_trips_df_v2 %>%  group_by(year_month) %>% summarise(count = length(ride_id),'%' = (length(ride_id) / nrow(all_trips_df_v2)) * 100,
'members_percent' = (sum(member_casual == "member") / length(ride_id)) * 100,"Casual_percent" = (sum(member_casual == "casual") / length(ride_id)) * 100, 'Member x Casual perc Differ' = members_percent - Casual_percent)
```

```{r}
all_trips_df_v2 %>% ggplot() + geom_bar(mapping = aes(x=year_month,fill= member_casual)) + labs(x="Month",title = "Chart 02 - Distribution by month") + coord_flip()
```


Some key takeaways can be taken by this chart: -- 
* There's more riders in summer season as compared to winter season.
* The month with the biggest count of data points was August.
* In all month we hae more members riders than casual riders.

##### Weekday

How much of the data is distributed by weekday?

```{r}
all_trips_df_v2 %>% group_by(day_of_week) %>% summarise(count = length(ride_id),'%' = (length(ride_id)/nrow(all_trips_df_v2))*100,'members_percent' = (sum(member_casual == "member") / length(ride_id))*100,
    'casual_percent' = (sum(member_casual == "casual")/length(ride_id))*100,'Member X Casual Perc Differ' = members_percent-casual_percent)
```
```{r}
ggplot(all_trips_df_v2)+geom_bar(mapping = aes(x=day_of_week,fill = member_casual)) + labs(x="Weekday",title = "Chart 03 - Distribution by weekdasy") + coord_flip()
```

Some key takeaways can be taken by this chart: -- 
* The biggest volume of data is on weekdays.
* weekends has the smallest data points.
* weekends has the biggest volume of casual, starting on Friday.


##### ride time

```{r}
ventiles = quantile(all_trips_df_v2$ride_length, seq(0,1,by = 0.05))
ventiles
```


```{r}
all_trips_outliers <- all_trips_df_v2 %>% filter(ride_length > as.numeric(ventiles['5%'])) %>% filter(ride_length < as.numeric(ventiles["95%"]))

print(paste("Removed",nrow(all_trips_df_v2) - nrow(all_trips_outliers),"row as outliers" ))
```

```{r}
all_trips_outliers %>% group_by(member_casual) %>% 
  summarise(mean = mean(ride_length), 'first_quarter'
            = as.numeric(quantile(ride_length,.25)),
            'median' = median(ride_length), 'third_quarter'
            = as.numeric(quantile(ride_length,0.75)),
            'IR' = third_quarter - first_quarter)
```


```{r}
ggplot(all_trips_outliers, aes(x = member_casual, y = ride_length, fill = member_casual)) + labs(x= "member x Casual", y = "Riding time", title = "chart 04 - Distribution of riding time for Casual x member") + geom_boxplot()
```

It's Important to note that:
* Casual have more riding time than members.
* Mean and IQR is also bigger for casual.

```{r}
ggplot(all_trips_outliers) + geom_boxplot(mapping = aes(x=day_of_week, y=ride_length,fill = member_casual)) +
  facet_wrap(~ member_casual) + labs(x = "weekday",y = "Riding time",title = "chart 05 - Distribution of Riding for day of the week") + coord_flip()
```


### Guiding queestions
+ **How should you organize your data to perform analysis on it?**

All dataset has been organized into a single csv.

+ **Has your data been properly formatted?**

Yes, all the columns have their correct data type.

+ **what surprises did you discover in the data?**

One of the main surprises is how members differ from casuals when analysed from weekdays. Also the members have less riding time than casual.

+ **what trends or relationships did you find in the data?**

* There are more members than casuals in the dataset.
* There are more of a difference between the flow of members/casual fro midweek to weekends.
* Members use bikes on schedules that differs from casual.
* Members have less riding time.

+ **How will these insight help answer your business questions?**

This insight helps to build a profile for members.

### Key Tasks
* [X] Aggregate your data so it's useful and accessible.
* [X] Organize and format your data.
* [X] Perform calculations.
* [X  Identify trends and relationships.

### Deliverable
* [X] A summary of your analysis.


## Share
The share phase is usually done by building a presentation.

Let's go through the main finds and try to arrive at a conclusion.

What we know about the dataset:

+ Members have the biggest proportion of the dataset, ~53% bigger than casual.
+ The month with the biggest count of data points was August.
+ In all months we have more member's rides than casual rides.
+ Temperature heavily influences the volume of rides in the month.
Now how members differs from casuals:
+ Members have the biggest volume of data.
+ Casuals have more riding time than members.

### Guiding questions
+ **Were you able to answer the question of how annual members and casual riders use Cyclist bikes differently?**

Yes. The data points to several differences between casuals and members.

+ **How do your findings relate to your original question?**

The findings build a profile for members, relating to "Find the keys differences between casuals and annual riders", also knowing whey they use the bikes helps to find "How digital media could influence them".

+ **Who is your audience? What is the best way to communicate with them?**

The main target audience is my cyclistic marketing analytics team and Lily Moreno. The best way to communicate is through a slide presentation of the findings.

+ **Can data visualization help you share your findings?**

Yes, the main core of the finds is through data visualization.

+ **Is your presentation accessible to your audience?**

Yes, the plots were made using vibrant colors, and corresponding labels.

### Key tasks

* [X] Determine the best way to share your findings.
* [X] Create effective data visualizations.
* [X] Present your findings.
* [X] Ensure your work is accessible.

### Deliverable

* [X] Supporting visualizations and key findings.

## Act 
The act phase would be done by the marketing team of the company. The main takeaway will be the top three recommendations for the marketing.

### Guiding questions
+ **What is your final conclusion based on your analysis?**

Members and casual have different habits when using the bikes.

+ **How could your team and business apply your insights?**

The insight could be implemented when preparing a marketing campaign for turning casual into members.

+ **What next steps would you or your stakeholders take based on your findings?**

Further analysis could be done to improve the findings, besides that, the marketing team can take the main information to build a marketing campaign.

+ **Is there additional data you could use to expand on your findings?**

+ Mobility data.
+ Improved climate data.
+ More information members.

### Deliverable
+ My top three recommendations based on analysis:

* 1. Build a marketing campaign focusing on show how bikes help people to get to work, while maintaining the planet green and avoid traffic. The ads could be show on professional social networks.
* 2. Increase benefits for riding during cold months. Coupons and discounts could be handed out.
+ 3. As the bikes are also used for recreations on the weekends, ads campaigns could also be made showing people using the bikes for exercise during the weeks. The ads could focus on how practical and **consistent** the bikes can be.

## Conclusion

The Google Analytics Professional Certificate teaches me a lot and the R language is really useful for analyzing data.